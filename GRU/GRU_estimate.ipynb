{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras_preprocessing.sequence import TimeseriesGenerator\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.src.layers import LSTM, GRU, RNN, Dense, Flatten\n",
    "from keras.src.optimizers.rmsprop import RMSprop\n",
    "from keras.src.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.src.models.model import model_from_json\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_DST_007 생성 완료\n",
      "csv_DST_008 생성 완료\n",
      "csv_FUDS_007 생성 완료\n",
      "csv_FUDS_008 생성 완료\n",
      "csv_US06_007 생성 완료\n",
      "csv_US06_008 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 온도 선택 [N10, 0, 10, 20, 25, 30, 40, 50], temp 변수에 설정\n",
    "\n",
    "temp = '20'\n",
    "mode = ['DST', 'FUDS' ,'US06']\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "for m in mode:\n",
    "    data_dir = os.path.join(parent_dir, f'DB Preprocessing/refined_data/{temp}/{m}')\n",
    "    file_names = os.listdir(data_dir)\n",
    "    for file_name in file_names:\n",
    "        csv_dir = os.path.join(data_dir, file_name)\n",
    "        if '007' in file_name:\n",
    "            num = '007'\n",
    "        else: \n",
    "            num = '008'\n",
    "        globals()['csv_{}'.format(f'{m}_{num}')] = pd.DataFrame(pd.read_csv(csv_dir))\n",
    "        print(f'csv_{m}_{num} 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current(A)</th>\n",
       "      <th>Voltage(V)</th>\n",
       "      <th>Temperature (C)_1</th>\n",
       "      <th>SoC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>3.551529</td>\n",
       "      <td>20.038303</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>3.551221</td>\n",
       "      <td>20.144194</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>3.551221</td>\n",
       "      <td>20.069010</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>3.550606</td>\n",
       "      <td>20.069010</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.550606</td>\n",
       "      <td>20.144194</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>-0.480845</td>\n",
       "      <td>2.154227</td>\n",
       "      <td>20.574072</td>\n",
       "      <td>0.032111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>-0.480845</td>\n",
       "      <td>2.113601</td>\n",
       "      <td>20.679928</td>\n",
       "      <td>0.023337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>-0.480845</td>\n",
       "      <td>2.070204</td>\n",
       "      <td>20.512659</td>\n",
       "      <td>0.014475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>-0.480845</td>\n",
       "      <td>2.027424</td>\n",
       "      <td>20.512659</td>\n",
       "      <td>0.005616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>-0.480845</td>\n",
       "      <td>1.999724</td>\n",
       "      <td>20.587812</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7303 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Current(A)  Voltage(V)  Temperature (C)_1        SoC\n",
       "0       0.000191    3.551529          20.038303  80.000000\n",
       "1       0.000191    3.551221          20.144194  80.000000\n",
       "2       0.000191    3.551221          20.069010  80.000000\n",
       "3       0.000191    3.550606          20.069010  80.000000\n",
       "4       0.000003    3.550606          20.144194  80.000000\n",
       "...          ...         ...                ...        ...\n",
       "7298   -0.480845    2.154227          20.574072   0.032111\n",
       "7299   -0.480845    2.113601          20.679928   0.023337\n",
       "7300   -0.480845    2.070204          20.512659   0.014475\n",
       "7301   -0.480845    2.027424          20.512659   0.005616\n",
       "7302   -0.480845    1.999724          20.587812   0.000000\n",
       "\n",
       "[7303 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_DST_007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. V, I, T / SoC 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_DST_007 생성 완료\n",
      "output_DST_007 생성 완료\n",
      "input_DST_008 생성 완료\n",
      "output_DST_008 생성 완료\n",
      "input_FUDS_007 생성 완료\n",
      "output_FUDS_007 생성 완료\n",
      "input_FUDS_008 생성 완료\n",
      "output_FUDS_008 생성 완료\n",
      "input_US06_007 생성 완료\n",
      "output_US06_007 생성 완료\n",
      "input_US06_008 생성 완료\n",
      "output_US06_008 생성 완료\n"
     ]
    }
   ],
   "source": [
    "num = ['007','008']\n",
    "\n",
    "def df2numpy(df):\n",
    "    np = df.values\n",
    "    return np\n",
    "\n",
    "for m in mode:\n",
    "    for n in num:\n",
    "        var_name = f'csv_{m}_{n}'\n",
    "        csv = globals()[var_name]\n",
    "        globals()[f'input_{m}_{n}'] = df2numpy(csv[['Current(A)', 'Voltage(V)', 'Temperature (C)_1']])\n",
    "        print(f'input_{m}_{n} 생성 완료')\n",
    "        globals()[f'output_{m}_{n}'] = df2numpy(csv[['SoC']])\n",
    "        print(f'output_{m}_{n} 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7303, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.90588195e-04,  3.55152917e+00,  2.00383034e+01],\n",
       "       [ 1.90588195e-04,  3.55122137e+00,  2.01441936e+01],\n",
       "       [ 1.90588195e-04,  3.55122137e+00,  2.00690098e+01],\n",
       "       ...,\n",
       "       [-4.80844796e-01,  2.07020450e+00,  2.05126591e+01],\n",
       "       [-4.80844796e-01,  2.02742362e+00,  2.05126591e+01],\n",
       "       [-4.80844796e-01,  1.99972391e+00,  2.05878124e+01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_DST_007.shape)\n",
    "input_DST_007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7055, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.70769058e-04,  3.55244279e+00,  2.01151886e+01],\n",
       "       [-4.51222935e-04,  3.55213499e+00,  2.00844650e+01],\n",
       "       [-4.51222935e-04,  3.55213499e+00,  2.00537434e+01],\n",
       "       ...,\n",
       "       [-4.58082289e-01,  2.16408896e+00,  1.98769798e+01],\n",
       "       [-8.25125515e-01,  2.03082442e+00,  1.98769798e+01],\n",
       "       [-8.24945033e-01,  1.99881625e+00,  1.99076920e+01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_US06_008.shape)\n",
    "input_US06_008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input, output, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(input) - look_back + 1):\n",
    "        a = input[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(output[i + look_back -1])\n",
    "    dataY = np.reshape(dataY, (len(dataY), 1, 1))\n",
    "    print(dataY.shape)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7284, 1, 1)\n",
      "(7421, 1, 1)\n",
      "(6879, 1, 1)\n",
      "(7036, 1, 1)\n",
      "(7279, 1, 1)\n",
      "(7526, 1, 1)\n",
      "(7284, 20, 3)\n",
      "(7284, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# look_back 변수 설정(자연수. 보통 20 설정.)\n",
    "look_back = 20\n",
    "\n",
    "dstX_7, dstY_7 = create_dataset(input_DST_007, output_DST_007, look_back)\n",
    "dstX_8, dstY_8 = create_dataset(input_DST_008, output_DST_008, look_back)\n",
    "us06X_7, us06Y_7 = create_dataset(input_US06_007, output_US06_007, look_back)\n",
    "us06X_8, us06Y_8 = create_dataset(input_US06_008, output_US06_008, look_back)\n",
    "fudsX_7, fudsY_7 = create_dataset(input_FUDS_007, output_FUDS_007, look_back)\n",
    "fudsX_8, fudsY_8 = create_dataset(input_FUDS_008, output_FUDS_008, look_back)\n",
    "\n",
    "print(dstX_7.shape)\n",
    "print(dstY_7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ays99\\Documents\\2024 대학\\1학기\\캡디\\project\\SoC_capstone\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(512, input_shape=(look_back, 3), return_sequences=True, activation='relu'))\n",
    "model.add(GRU(128, return_sequences=True, activation='relu'))\n",
    "model.add(GRU(8, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# optimizer는 알고리즘 종류.\n",
    "# SGD, RMSprop, Adagrad, Adadelta, Adam이 있음(Adam이 가장많이 사용 됨)\n",
    "# loss는 정답과 예측값을 비교하는 모델. 회귀에서 사용.\n",
    "# 모델의 성능을 올리기 위해 loss 임의 변형 가능. 근데 우리는 mse 사용.\n",
    "# metrics는 평가 지표. 모델의 성능을 평가할 때 사용\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m history_dst_7 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(dstX_7, dstY_7, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(fudsX_7, fudsY_7), verbose\u001b[38;5;241m=\u001b[39mverbose, shuffle\u001b[38;5;241m=\u001b[39mshuffle, callbacks \u001b[38;5;241m=\u001b[39m [early_stopping])\n\u001b[0;32m     20\u001b[0m history_us06_7 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(us06X_7, us06Y_7, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(fudsX_7, fudsY_7), verbose\u001b[38;5;241m=\u001b[39mverbose, shuffle\u001b[38;5;241m=\u001b[39mshuffle, callbacks \u001b[38;5;241m=\u001b[39m [early_stopping])\n\u001b[1;32m---> 21\u001b[0m history_dst_8 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdstX_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdstY_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfudsX_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfudsY_8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m history_us06_8 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(us06X_8, us06Y_8, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(fudsX_8, fudsY_8), verbose\u001b[38;5;241m=\u001b[39mverbose, shuffle\u001b[38;5;241m=\u001b[39mshuffle, callbacks \u001b[38;5;241m=\u001b[39m [early_stopping])\n",
      "File \u001b[1;32mc:\\Users\\ays99\\Documents\\2024 대학\\1학기\\캡디\\project\\SoC_capstone\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ays99\\Documents\\2024 대학\\1학기\\캡디\\project\\SoC_capstone\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:313\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m--> 313\u001b[0m         \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n",
      "File \u001b[1;32mc:\\Users\\ays99\\Documents\\2024 대학\\1학기\\캡디\\project\\SoC_capstone\\venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:98\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m     96\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     99\u001b[0m     logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "# epochs는 전체 데이터를 학습에 사용하는 수 / underfitting overfitting의 원인\n",
    "# epochs = 40이라면 40바퀴 돌린다고 생각하면 됨\n",
    "# batch_size는 잘라서 주는 수\n",
    "# 데이터가 2000개, epochs=20, batch_size=500이라면\n",
    "# 1 epoch는 데이터 사이즈가 500인 batch가 들어간 4번의 iteration으로 들어감\n",
    "# 전체 데이터 셋에 대해서는 총 20번의 학습, iteration 기준으로는 총 80번의 학습\n",
    "# verbose는 그냥 돌아가는 과정을 출력하는것. 2는 epoch마다 한 줄 씩 출력.\n",
    "# 스크롤 귀찮으면 안해도 될듯\n",
    "# shuffle은 학습 시 데이터 순서를 섞어서 주는 것\n",
    "# 비교해봤는데 True로 놓는게 오차율이 적다\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "verbose = 0\n",
    "shuffle = True\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "history_dst_7 = model.fit(dstX_7, dstY_7, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_7, fudsY_7), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_us06_7 = model.fit(us06X_7, us06Y_7, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_7, fudsY_7), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_dst_8 = model.fit(dstX_8, dstY_8, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_8, fudsY_8), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_us06_8 = model.fit(us06X_8, us06Y_8, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_8, fudsY_8), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_dir = os.path.join(current_dir, 'model', temp)\n",
    "model_json = model.to_json()\n",
    "open(f'{model_dir}/{temp}_model.json', 'w').write(model_json)\n",
    "\n",
    "# save model's learned weights\n",
    "model.save_weights(f'{model_dir}/{temp}.weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "json_file = open(f'{model_dir}/{temp}_model.json', \"r\")\n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# model weight load \n",
    "loaded_model.load_weights(f'{model_dir}/{temp}.weights.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_dst_7.history['loss'], label='train')\n",
    "plt.plot(history_dst_7.history['val_loss'], label='test')\n",
    "plt.title(\"007_loss\")\n",
    "plt.legend() \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_dst_8.history['loss'], label='train')\n",
    "plt.plot(history_dst_8.history['val_loss'], label='test')\n",
    "plt.title(\"008_loss\")\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoC 예측 정답 비교 Plot\n",
    "fudsY_7_hat = model.predict(fudsX_7)\n",
    "fudsY_8_hat = model.predict(fudsX_8)\n",
    "fudsY_7 = np.reshape(fudsY_7, (fudsY_7.shape[0], 1))\n",
    "fudsY_8 = np.reshape(fudsY_8, (fudsY_8.shape[0], 1))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fudsY_7_hat, label='Prediction')\n",
    "plt.plot(fudsY_7, label='Real data')\n",
    "plt.title(\"007_SoC\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fudsY_8_hat, label='Prediction')\n",
    "plt.plot(fudsY_8, label='Real data')\n",
    "plt.title(\"008_SoC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 007, 008 배터리 RMSE, MAE\n",
    "rmse = math.sqrt(mean_squared_error(fudsY_7, fudsY_7_hat))\n",
    "mae = mean_absolute_error(fudsY_7, fudsY_7_hat)\n",
    "print('Test 007 RMSE: %.3f' % rmse)\n",
    "print('Test 007 MAE: %.3f' % mae)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(fudsY_8, fudsY_8_hat))\n",
    "mae = mean_absolute_error(fudsY_8, fudsY_8_hat)\n",
    "print('Test 008 RMSE: %.3f' % rmse)\n",
    "print('Test 008 MAE: %.3f' % mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
