{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras_preprocessing.sequence import TimeseriesGenerator\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.src.layers import LSTM, GRU, RNN, Dense, Flatten\n",
    "from keras.src.optimizers.rmsprop import RMSprop\n",
    "from keras.src.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.src.models.model import model_from_json\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 온도 선택 [N10, 0, 10, 20, 25, 30, 40, 50], temp 변수에 설정\n",
    "\n",
    "temp = '20'\n",
    "mode = ['DST', 'FUDS' ,'US06']\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "for m in mode:\n",
    "    data_dir = os.path.join(parent_dir, f'DB Preprocessing/refined_data/{temp}/{m}')\n",
    "    file_names = os.listdir(data_dir)\n",
    "    for file_name in file_names:\n",
    "        csv_dir = os.path.join(data_dir, file_name)\n",
    "        if '007' in file_name:\n",
    "            num = '007'\n",
    "        else: \n",
    "            num = '008'\n",
    "        globals()['csv_{}'.format(f'{m}_{num}')] = pd.DataFrame(pd.read_csv(csv_dir))\n",
    "        print(f'csv_{m}_{num} 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_DST_007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. V, I, T / SoC 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['007','008']\n",
    "\n",
    "def df2numpy(df):\n",
    "    np = df.values\n",
    "    return np\n",
    "\n",
    "for m in mode:\n",
    "    for n in num:\n",
    "        var_name = f'csv_{m}_{n}'\n",
    "        csv = globals()[var_name]\n",
    "        globals()[f'input_{m}_{n}'] = df2numpy(csv[['Current(A)', 'Voltage(V)', 'Temperature (C)_1']])\n",
    "        print(f'input_{m}_{n} 생성 완료')\n",
    "        globals()[f'output_{m}_{n}'] = df2numpy(csv[['SoC']])\n",
    "        print(f'output_{m}_{n} 생성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_DST_007.shape)\n",
    "input_DST_007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_US06_008.shape)\n",
    "input_US06_008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input, output, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(input) - look_back + 1):\n",
    "        a = input[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(output[i + look_back -1])\n",
    "    dataY = np.reshape(dataY, (len(dataY), 1, 1))\n",
    "    print(dataY.shape)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back 변수 설정(자연수. 보통 20 설정.)\n",
    "look_back = 20\n",
    "\n",
    "dstX_7, dstY_7 = create_dataset(input_DST_007, output_DST_007, look_back)\n",
    "dstX_8, dstY_8 = create_dataset(input_DST_008, output_DST_008, look_back)\n",
    "us06X_7, us06Y_7 = create_dataset(input_US06_007, output_US06_007, look_back)\n",
    "us06X_8, us06Y_8 = create_dataset(input_US06_008, output_US06_008, look_back)\n",
    "fudsX_7, fudsY_7 = create_dataset(input_FUDS_007, output_FUDS_007, look_back)\n",
    "fudsX_8, fudsY_8 = create_dataset(input_FUDS_008, output_FUDS_008, look_back)\n",
    "\n",
    "print(dstX_7.shape)\n",
    "print(dstY_7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(512, input_shape=(look_back, 3), return_sequences=True, activation='relu'))\n",
    "model.add(GRU(128, return_sequences=True, activation='relu'))\n",
    "model.add(GRU(8, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# optimizer는 알고리즘 종류.\n",
    "# SGD, RMSprop, Adagrad, Adadelta, Adam이 있음(Adam이 가장많이 사용 됨)\n",
    "# loss는 정답과 예측값을 비교하는 모델. 회귀에서 사용.\n",
    "# 모델의 성능을 올리기 위해 loss 임의 변형 가능. 근데 우리는 mse 사용.\n",
    "# metrics는 평가 지표. 모델의 성능을 평가할 때 사용\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "# epochs는 전체 데이터를 학습에 사용하는 수 / underfitting overfitting의 원인\n",
    "# epochs = 40이라면 40바퀴 돌린다고 생각하면 됨\n",
    "# batch_size는 잘라서 주는 수\n",
    "# 데이터가 2000개, epochs=20, batch_size=500이라면\n",
    "# 1 epoch는 데이터 사이즈가 500인 batch가 들어간 4번의 iteration으로 들어감\n",
    "# 전체 데이터 셋에 대해서는 총 20번의 학습, iteration 기준으로는 총 80번의 학습\n",
    "# verbose는 그냥 돌아가는 과정을 출력하는것. 2는 epoch마다 한 줄 씩 출력.\n",
    "# 스크롤 귀찮으면 안해도 될듯\n",
    "# shuffle은 학습 시 데이터 순서를 섞어서 주는 것\n",
    "# 비교해봤는데 True로 놓는게 오차율이 적다\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "verbose = 0\n",
    "shuffle = True\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "history_dst_7 = model.fit(dstX_7, dstY_7, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_7, fudsY_7), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_us06_7 = model.fit(us06X_7, us06Y_7, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_7, fudsY_7), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_dst_8 = model.fit(dstX_8, dstY_8, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_8, fudsY_8), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])\n",
    "history_us06_8 = model.fit(us06X_8, us06Y_8, epochs=epochs, batch_size=batch_size, validation_data=(fudsX_8, fudsY_8), verbose=verbose, shuffle=shuffle, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_dir = os.path.join(current_dir, 'model', temp)\n",
    "model_json = model.to_json()\n",
    "open(f'{model_dir}/{temp}_model.json', 'w').write(model_json)\n",
    "\n",
    "# save model's learned weights\n",
    "model.save_weights(f'{model_dir}/{temp}.weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "json_file = open(f'{model_dir}/{temp}_model.json', \"r\")\n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# model weight load \n",
    "loaded_model.load_weights(f'{model_dir}/{temp}.weights.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_dst_7.history['loss'], label='train')\n",
    "plt.plot(history_dst_7.history['val_loss'], label='test')\n",
    "plt.title(\"007_loss\")\n",
    "plt.legend() \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_dst_8.history['loss'], label='train')\n",
    "plt.plot(history_dst_8.history['val_loss'], label='test')\n",
    "plt.title(\"008_loss\")\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoC 예측 정답 비교 Plot\n",
    "fudsY_7_hat = model.predict(fudsX_7)\n",
    "fudsY_8_hat = model.predict(fudsX_8)\n",
    "fudsY_7 = np.reshape(fudsY_7, (fudsY_7.shape[0], 1))\n",
    "fudsY_8 = np.reshape(fudsY_8, (fudsY_8.shape[0], 1))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fudsY_7_hat, label='Prediction')\n",
    "plt.plot(fudsY_7, label='Real data')\n",
    "plt.title(\"007_SoC\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fudsY_8_hat, label='Prediction')\n",
    "plt.plot(fudsY_8, label='Real data')\n",
    "plt.title(\"008_SoC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 007, 008 배터리 RMSE, MAE\n",
    "rmse = math.sqrt(mean_squared_error(fudsY_7, fudsY_7_hat))\n",
    "mae = mean_absolute_error(fudsY_7, fudsY_7_hat)\n",
    "print('Test 007 RMSE: %.3f' % rmse)\n",
    "print('Test 007 MAE: %.3f' % mae)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(fudsY_8, fudsY_8_hat))\n",
    "mae = mean_absolute_error(fudsY_8, fudsY_8_hat)\n",
    "print('Test 008 RMSE: %.3f' % rmse)\n",
    "print('Test 008 MAE: %.3f' % mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
